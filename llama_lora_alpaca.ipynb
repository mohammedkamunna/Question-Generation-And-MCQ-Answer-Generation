{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiirsHhyztBF",
        "outputId": "30f13f26-e38c-4569-933f-f5435ca0c0ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'alpaca-lora'...\n",
            "remote: Enumerating objects: 339, done.\u001b[K\n",
            "remote: Total 339 (delta 0), reused 0 (delta 0), pack-reused 339\u001b[K\n",
            "Receiving objects: 100% (339/339), 13.79 MiB | 15.33 MiB/s, done.\n",
            "Resolving deltas: 100% (201/201), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/daanelson/alpaca-lora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MX6dGbkzxRl",
        "outputId": "b95185b5-7f18-41c3-e211-880ebedd17b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/alpaca-lora\n"
          ]
        }
      ],
      "source": [
        "cd alpaca-lora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3BiafOEtc03",
        "outputId": "0056c99f-eb8a-478e-9381-fffbba378bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers.git (from -r requirements.txt (line 4))\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-f1vllagn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-f1vllagn\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 67239f736059fd52675e49237bdc79e4c9b0a462\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/huggingface/peft.git (from -r requirements.txt (line 7))\n",
            "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-o1iym0xa\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-o1iym0xa\n",
            "  Resolved https://github.com/huggingface/peft.git to commit 52ff0cde9f2cc64059e171c2cfd94512914c85df\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting datasets (from -r requirements.txt (line 1))\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting loralib (from -r requirements.txt (line 2))\n",
            "  Downloading loralib-0.1.2-py3-none-any.whl (10 kB)\n",
            "Collecting sentencepiece (from -r requirements.txt (line 3))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate (from -r requirements.txt (line 5))\n",
            "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes (from -r requirements.txt (line 6))\n",
            "  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio (from -r requirements.txt (line 8))\n",
            "  Downloading gradio-3.45.2-py3-none-any.whl (20.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->-r requirements.txt (line 1))\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (4.66.1)\n",
            "Collecting xxhash (from datasets->-r requirements.txt (line 1))\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->-r requirements.txt (line 1))\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (3.8.5)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets->-r requirements.txt (line 1))\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0.dev0->-r requirements.txt (line 4)) (3.12.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0.dev0->-r requirements.txt (line 4)) (2023.6.3)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers==4.34.0.dev0->-r requirements.txt (line 4))\n",
            "  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers==4.34.0.dev0->-r requirements.txt (line 4))\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 5)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 5)) (2.0.1+cu118)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 8))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 8)) (4.2.2)\n",
            "Collecting fastapi (from gradio->-r requirements.txt (line 8))\n",
            "  Downloading fastapi-0.103.2-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio->-r requirements.txt (line 8))\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.5.3 (from gradio->-r requirements.txt (line 8))\n",
            "  Downloading gradio_client-0.5.3-py3-none-any.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.4/298.4 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio->-r requirements.txt (line 8))\n",
            "  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 8)) (6.0.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 8)) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 8)) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 8)) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio->-r requirements.txt (line 8))\n",
            "  Downloading orjson-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 8)) (9.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 8)) (1.10.12)\n",
            "Collecting pydub (from gradio->-r requirements.txt (line 8))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio->-r requirements.txt (line 8))\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 8))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 8)) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 8))\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio->-r requirements.txt (line 8))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 8)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 8)) (4.19.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 8)) (0.12.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 8)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 8)) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 8)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 8)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 1)) (2023.3.post1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (2023.7.22)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets->-r requirements.txt (line 1))\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 5)) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate->-r requirements.txt (line 5)) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate->-r requirements.txt (line 5)) (16.0.6)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 8)) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 8))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio->-r requirements.txt (line 8)) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio->-r requirements.txt (line 8))\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.19.0,>=0.18.0 (from httpx->gradio->-r requirements.txt (line 8))\n",
            "  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio->-r requirements.txt (line 8)) (1.1.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 8)) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 8)) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 8)) (0.10.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio->-r requirements.txt (line 8)) (1.16.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate->-r requirements.txt (line 5)) (1.3.0)\n",
            "Building wheels for collected packages: transformers, peft, ffmpy\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.34.0.dev0-py3-none-any.whl size=7745690 sha256=721cd333f75926a0046d0e5a3642e4c114aaa459749a39f2b61dff31ffebb9e1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bv_cvbeq/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.6.0.dev0-py3-none-any.whl size=111134 sha256=a8258dddb8e65882fd3759cc05c03e45705f1f174b3041742b482c6d5098bc68\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bv_cvbeq/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=b8e2c38a09add24b2728b62ad31ad6befa0e82e34ad782c864dd55f909fced00\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built transformers peft ffmpy\n",
            "Installing collected packages: sentencepiece, safetensors, pydub, ffmpy, bitsandbytes, xxhash, websockets, semantic-version, python-multipart, orjson, loralib, h11, dill, aiofiles, uvicorn, starlette, multiprocess, huggingface-hub, httpcore, tokenizers, httpx, fastapi, transformers, gradio-client, datasets, gradio, accelerate, peft\n",
            "Successfully installed accelerate-0.23.0 aiofiles-23.2.1 bitsandbytes-0.41.1 datasets-2.14.5 dill-0.3.7 fastapi-0.103.2 ffmpy-0.3.1 gradio-3.45.2 gradio-client-0.5.3 h11-0.14.0 httpcore-0.18.0 httpx-0.25.0 huggingface-hub-0.16.4 loralib-0.1.2 multiprocess-0.70.15 orjson-3.9.7 peft-0.6.0.dev0 pydub-0.25.1 python-multipart-0.0.6 safetensors-0.3.3 semantic-version-2.10.0 sentencepiece-0.1.99 starlette-0.27.0 tokenizers-0.14.0 transformers-4.34.0.dev0 uvicorn-0.23.2 websockets-11.0.3 xxhash-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161,
          "referenced_widgets": [
            "820894f68fde40e9951d5561df4365ab",
            "e0f5b279cc8244c09ef9cd5c82bcdf8e",
            "7ab84b901442487884ca1c4ea2f9db30",
            "f12fb5e1a3e84d50908403da32a2096d",
            "3fb918ca79724fbaa25bc527e43bb535",
            "7bf641cab7384731a1186a2462e57bce",
            "3bfc37279d2748ef9262e3642282b026",
            "89f6216e60494dcc857a756e47aed9f9",
            "3a06f4cb00734e5ea64954c04cf3cfd5",
            "2a5ac654b01b4eb99fc1426352ac4be7",
            "b34cfaf7d7f24839a6068c25a335fd42"
          ]
        },
        "id": "OnDd0yXhtbmj",
        "outputId": "96532be9-2984-4fc3-8a17-664a3694bb66"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "820894f68fde40e9951d5561df4365ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
            "The class this function is called from is 'LlamaTokenizer'.\n",
            "Loading the tokenizer from the `special_tokens_map.json` and the `added_tokens.json` will be removed in `transformers 5`,  it is kept for forward compatibility, but it is recommended to update your `tokenizer_config.json` by uploading it again. You will see the new `added_tokens_decoder` attribute that will store the relevant information.\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import bitsandbytes as bnb\n",
        "from datasets import load_dataset\n",
        "import transformers\n",
        "\n",
        "assert (\n",
        "    \"LlamaTokenizer\" in transformers._import_structure[\"models.llama\"]\n",
        "), \"LLaMA is now in HuggingFace's main branch.\\nPlease reinstall it: pip uninstall transformers && pip install git+https://github.com/huggingface/transformers.git\"\n",
        "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
        "from peft import (\n",
        "    prepare_model_for_int8_training,\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    get_peft_model_state_dict,\n",
        ")\n",
        "\n",
        "\n",
        "# optimized for RTX 4090. for larger GPUs, increase some of these?\n",
        "MICRO_BATCH_SIZE = 4  # this could actually be 5 but i like powers of 2\n",
        "BATCH_SIZE = 128\n",
        "GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\n",
        "EPOCHS = 3  # we don't always need 3 tbhtmu\n",
        "LEARNING_RATE = 3e-4  # the Karpathy constant\n",
        "CUTOFF_LEN = 256  # 256 accounts for about 96% of the data\n",
        "LORA_R = 8\n",
        "LORA_ALPHA = 16\n",
        "LORA_DROPOUT = 0.05\n",
        "VAL_SET_SIZE = 2000\n",
        "TARGET_MODULES = [\n",
        "    \"q_proj\",\n",
        "    \"v_proj\",\n",
        "]\n",
        "DATA_PATH = \"alpaca_data_cleaned.json\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/ChatNTI/llama-lora-alpaca_\"\n",
        "\n",
        "device_map = \"auto\"\n",
        "world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n",
        "ddp = world_size != 1\n",
        "if ddp:\n",
        "    device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n",
        "    GRADIENT_ACCUMULATION_STEPS = GRADIENT_ACCUMULATION_STEPS // world_size\n",
        "\n",
        "model = LlamaForCausalLM.from_pretrained(\n",
        "    \"decapoda-research/llama-7b-hf\",\n",
        "    load_in_8bit=True,\n",
        "    device_map=device_map,\n",
        ")\n",
        "tokenizer = LlamaTokenizer.from_pretrained(\n",
        "    \"decapoda-research/llama-7b-hf\", add_eos_token=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCydwmR03vWv",
        "outputId": "796e5b0c-e8a0-424e-d904-d276ef1b0c2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaAttention(\n",
              "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
              "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
              "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
              "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
              "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
              "          (act_fn): SiLUActivation()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm()\n",
              "        (post_attention_layernorm): LlamaRMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = prepare_model_for_int8_training(model)\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=LORA_R,\n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    target_modules=TARGET_MODULES,\n",
        "    lora_dropout=LORA_DROPOUT,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "model = get_peft_model(model, config)\n",
        "tokenizer.pad_token_id = 0  # unk. we want this to be different from the eos token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmS-onIVu8-e",
        "outputId": "0fe2bc95-f05d-4d41-baf7-6678e830bd7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:133: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh1jJQ-du_r2",
        "outputId": "6756397d-94e3-4175-c328-5d7cb42bd1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): Linear8bitLt(\n",
              "                in_features=4096, out_features=4096, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
              "              (v_proj): Linear8bitLt(\n",
              "                in_features=4096, out_features=4096, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
              "              (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
              "              (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
              "              (act_fn): SiLUActivation()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm()\n",
              "            (post_attention_layernorm): LlamaRMSNorm()\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4fPCSGq4C0-",
        "outputId": "a72b6d66-d410-4fc6-de2d-a29268652e3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base_model.model.model.embed_tokens.weight\n",
            "base_model.model.model.layers.0.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.0.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.0.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.0.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.0.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.0.mlp.up_proj.weight\n",
            "base_model.model.model.layers.0.mlp.down_proj.weight\n",
            "base_model.model.model.layers.0.input_layernorm.weight\n",
            "base_model.model.model.layers.0.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.1.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.1.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.1.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.1.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.1.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.1.mlp.up_proj.weight\n",
            "base_model.model.model.layers.1.mlp.down_proj.weight\n",
            "base_model.model.model.layers.1.input_layernorm.weight\n",
            "base_model.model.model.layers.1.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.2.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.2.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.2.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.2.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.2.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.2.mlp.up_proj.weight\n",
            "base_model.model.model.layers.2.mlp.down_proj.weight\n",
            "base_model.model.model.layers.2.input_layernorm.weight\n",
            "base_model.model.model.layers.2.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.3.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.3.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.3.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.3.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.3.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.3.mlp.up_proj.weight\n",
            "base_model.model.model.layers.3.mlp.down_proj.weight\n",
            "base_model.model.model.layers.3.input_layernorm.weight\n",
            "base_model.model.model.layers.3.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.4.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.4.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.4.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.4.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.4.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.4.mlp.up_proj.weight\n",
            "base_model.model.model.layers.4.mlp.down_proj.weight\n",
            "base_model.model.model.layers.4.input_layernorm.weight\n",
            "base_model.model.model.layers.4.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.5.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.5.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.5.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.5.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.5.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.5.mlp.up_proj.weight\n",
            "base_model.model.model.layers.5.mlp.down_proj.weight\n",
            "base_model.model.model.layers.5.input_layernorm.weight\n",
            "base_model.model.model.layers.5.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.6.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.6.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.6.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.6.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.6.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.6.mlp.up_proj.weight\n",
            "base_model.model.model.layers.6.mlp.down_proj.weight\n",
            "base_model.model.model.layers.6.input_layernorm.weight\n",
            "base_model.model.model.layers.6.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.7.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.7.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.7.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.7.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.7.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.7.mlp.up_proj.weight\n",
            "base_model.model.model.layers.7.mlp.down_proj.weight\n",
            "base_model.model.model.layers.7.input_layernorm.weight\n",
            "base_model.model.model.layers.7.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.8.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.8.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.8.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.8.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.8.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.8.mlp.up_proj.weight\n",
            "base_model.model.model.layers.8.mlp.down_proj.weight\n",
            "base_model.model.model.layers.8.input_layernorm.weight\n",
            "base_model.model.model.layers.8.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.9.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.9.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.9.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.9.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.9.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.9.mlp.up_proj.weight\n",
            "base_model.model.model.layers.9.mlp.down_proj.weight\n",
            "base_model.model.model.layers.9.input_layernorm.weight\n",
            "base_model.model.model.layers.9.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.10.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.10.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.10.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.10.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.10.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.10.mlp.up_proj.weight\n",
            "base_model.model.model.layers.10.mlp.down_proj.weight\n",
            "base_model.model.model.layers.10.input_layernorm.weight\n",
            "base_model.model.model.layers.10.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.11.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.11.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.11.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.11.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.11.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.11.mlp.up_proj.weight\n",
            "base_model.model.model.layers.11.mlp.down_proj.weight\n",
            "base_model.model.model.layers.11.input_layernorm.weight\n",
            "base_model.model.model.layers.11.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.12.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.12.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.12.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.12.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.12.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.12.mlp.up_proj.weight\n",
            "base_model.model.model.layers.12.mlp.down_proj.weight\n",
            "base_model.model.model.layers.12.input_layernorm.weight\n",
            "base_model.model.model.layers.12.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.13.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.13.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.13.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.13.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.13.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.13.mlp.up_proj.weight\n",
            "base_model.model.model.layers.13.mlp.down_proj.weight\n",
            "base_model.model.model.layers.13.input_layernorm.weight\n",
            "base_model.model.model.layers.13.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.14.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.14.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.14.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.14.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.14.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.14.mlp.up_proj.weight\n",
            "base_model.model.model.layers.14.mlp.down_proj.weight\n",
            "base_model.model.model.layers.14.input_layernorm.weight\n",
            "base_model.model.model.layers.14.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.15.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.15.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.15.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.15.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.15.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.15.mlp.up_proj.weight\n",
            "base_model.model.model.layers.15.mlp.down_proj.weight\n",
            "base_model.model.model.layers.15.input_layernorm.weight\n",
            "base_model.model.model.layers.15.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.16.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.16.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.16.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.16.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.16.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.16.mlp.up_proj.weight\n",
            "base_model.model.model.layers.16.mlp.down_proj.weight\n",
            "base_model.model.model.layers.16.input_layernorm.weight\n",
            "base_model.model.model.layers.16.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.17.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.17.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.17.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.17.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.17.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.17.mlp.up_proj.weight\n",
            "base_model.model.model.layers.17.mlp.down_proj.weight\n",
            "base_model.model.model.layers.17.input_layernorm.weight\n",
            "base_model.model.model.layers.17.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.18.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.18.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.18.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.18.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.18.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.18.mlp.up_proj.weight\n",
            "base_model.model.model.layers.18.mlp.down_proj.weight\n",
            "base_model.model.model.layers.18.input_layernorm.weight\n",
            "base_model.model.model.layers.18.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.19.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.19.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.19.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.19.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.19.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.19.mlp.up_proj.weight\n",
            "base_model.model.model.layers.19.mlp.down_proj.weight\n",
            "base_model.model.model.layers.19.input_layernorm.weight\n",
            "base_model.model.model.layers.19.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.20.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.20.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.20.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.20.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.20.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.20.mlp.up_proj.weight\n",
            "base_model.model.model.layers.20.mlp.down_proj.weight\n",
            "base_model.model.model.layers.20.input_layernorm.weight\n",
            "base_model.model.model.layers.20.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.21.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.21.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.21.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.21.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.21.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.21.mlp.up_proj.weight\n",
            "base_model.model.model.layers.21.mlp.down_proj.weight\n",
            "base_model.model.model.layers.21.input_layernorm.weight\n",
            "base_model.model.model.layers.21.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.22.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.22.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.22.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.22.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.22.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.22.mlp.up_proj.weight\n",
            "base_model.model.model.layers.22.mlp.down_proj.weight\n",
            "base_model.model.model.layers.22.input_layernorm.weight\n",
            "base_model.model.model.layers.22.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.23.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.23.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.23.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.23.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.23.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.23.mlp.up_proj.weight\n",
            "base_model.model.model.layers.23.mlp.down_proj.weight\n",
            "base_model.model.model.layers.23.input_layernorm.weight\n",
            "base_model.model.model.layers.23.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.24.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.24.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.24.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.24.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.24.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.24.mlp.up_proj.weight\n",
            "base_model.model.model.layers.24.mlp.down_proj.weight\n",
            "base_model.model.model.layers.24.input_layernorm.weight\n",
            "base_model.model.model.layers.24.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.25.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.25.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.25.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.25.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.25.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.25.mlp.up_proj.weight\n",
            "base_model.model.model.layers.25.mlp.down_proj.weight\n",
            "base_model.model.model.layers.25.input_layernorm.weight\n",
            "base_model.model.model.layers.25.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.26.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.26.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.26.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.26.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.26.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.26.mlp.up_proj.weight\n",
            "base_model.model.model.layers.26.mlp.down_proj.weight\n",
            "base_model.model.model.layers.26.input_layernorm.weight\n",
            "base_model.model.model.layers.26.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.27.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.27.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.27.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.27.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.27.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.27.mlp.up_proj.weight\n",
            "base_model.model.model.layers.27.mlp.down_proj.weight\n",
            "base_model.model.model.layers.27.input_layernorm.weight\n",
            "base_model.model.model.layers.27.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.28.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.28.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.28.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.28.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.28.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.28.mlp.up_proj.weight\n",
            "base_model.model.model.layers.28.mlp.down_proj.weight\n",
            "base_model.model.model.layers.28.input_layernorm.weight\n",
            "base_model.model.model.layers.28.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.29.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.29.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.29.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.29.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.29.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.29.mlp.up_proj.weight\n",
            "base_model.model.model.layers.29.mlp.down_proj.weight\n",
            "base_model.model.model.layers.29.input_layernorm.weight\n",
            "base_model.model.model.layers.29.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.30.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.30.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.30.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.30.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.30.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.30.mlp.up_proj.weight\n",
            "base_model.model.model.layers.30.mlp.down_proj.weight\n",
            "base_model.model.model.layers.30.input_layernorm.weight\n",
            "base_model.model.model.layers.30.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.31.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.31.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.31.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight\n",
            "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight\n",
            "base_model.model.model.layers.31.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.31.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.31.mlp.up_proj.weight\n",
            "base_model.model.model.layers.31.mlp.down_proj.weight\n",
            "base_model.model.model.layers.31.input_layernorm.weight\n",
            "base_model.model.model.layers.31.post_attention_layernorm.weight\n",
            "base_model.model.model.norm.weight\n",
            "base_model.model.lm_head.weight\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qepcndx5aSsd",
        "outputId": "5f2e8bdf-88c9-4e05-b7db-df27d11b56d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(param.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "8782559ca0cb4c74ac74c6c7926f23d2",
            "8b57b8c2c5c446119f2e2f85f5dbcac3",
            "7df1586c644448f1874d854309248236",
            "aaff45aa894b4b4ebbf18bbe6fdf5948",
            "46e179100c9449618080476b947f85df",
            "96ea26c44f6d400a904fa087a46a544b",
            "a64ced2e192a46108372816e8d382841",
            "8b0dc896c3c2401ebbbc065dc6fcec69",
            "ad235e16402742758d7897528576ed9d",
            "6970843fd87247aa9929684e0a881ef1",
            "b1deb2454c71408288776c6b5d16aed6",
            "cd7e838632ea48579bd3c357b7436f76",
            "7ee858d1a02f42e2a1672e7102d106ad",
            "98767e931d6546f1b38954727e878d64",
            "65e03b47d35b47298e63c5ff1ebd88b3",
            "423d05dff87448ed85e353c417f41729",
            "c7160636e0e0410a8775f6f0078ef27c",
            "53e65c0ab3af4b1b829f1505f03afd83",
            "ae63829572b24e3e97e0d1e0be4cf52f",
            "0337c163fb10491dbe7e1df6d023e0ff",
            "fede4440e00e4f85ab5c786804bd0b98",
            "cff58cf8976d4da29fe6afd798dc2e4d"
          ]
        },
        "id": "484OcRznufKk",
        "outputId": "95cdccd0-6999-4c16-d0c5-be75d662e329"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/49942 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8782559ca0cb4c74ac74c6c7926f23d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd7e838632ea48579bd3c357b7436f76"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "data = load_dataset(\"json\", data_files=DATA_PATH)\n",
        "\n",
        "\n",
        "def generate_prompt(data_point):\n",
        "    # sorry about the formatting disaster gotta move fast\n",
        "    if data_point[\"input\"]:\n",
        "        return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{data_point[\"instruction\"]}\n",
        "\n",
        "### Input:\n",
        "{data_point[\"input\"]}\n",
        "\n",
        "### Response:\n",
        "{data_point[\"output\"]}\"\"\"\n",
        "    else:\n",
        "        return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{data_point[\"instruction\"]}\n",
        "\n",
        "### Response:\n",
        "{data_point[\"output\"]}\"\"\"\n",
        "\n",
        "\n",
        "def tokenize(prompt):\n",
        "    # there's probably a way to do this with the tokenizer settings\n",
        "    # but again, gotta move fast\n",
        "    result = tokenizer(\n",
        "        prompt,\n",
        "        truncation=True,\n",
        "        max_length=CUTOFF_LEN + 1,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "    return {\n",
        "        \"input_ids\": result[\"input_ids\"][:-1],\n",
        "        \"attention_mask\": result[\"attention_mask\"][:-1],\n",
        "    }\n",
        "\n",
        "\n",
        "def generate_and_tokenize_prompt(data_point):\n",
        "    prompt = generate_prompt(data_point)\n",
        "    return tokenize(prompt)\n",
        "\n",
        "\n",
        "if VAL_SET_SIZE > 0:\n",
        "    train_val = data[\"train\"].train_test_split(\n",
        "        test_size=VAL_SET_SIZE, shuffle=True, seed=42\n",
        "    )\n",
        "    train_data = train_val[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n",
        "    val_data = train_val[\"test\"].shuffle().map(generate_and_tokenize_prompt)\n",
        "else:\n",
        "    train_data = data[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n",
        "    val_data = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "2cb3f10f076d402994199134583f69a9",
            "03ddfe106bf248198691e2f7ff61450f",
            "02e78fe0f3a84e7085d892ba30d3592a",
            "7cf6ee1a47424cac992331483d5ad8b3",
            "7c80452949a747579eadcb1d31185168",
            "e08a8e866e804a6fa4307bf25cf13e07",
            "ed83a818c1fc447586478516a2dc4e7b",
            "6c9471145ac743fe9ed5ab19d8a36178",
            "ff259bd4733f4910b3219745e1618c55",
            "9251c5e978d34464aafb4abfddcce508",
            "5a56262fa299420190eea3a8d0faf669",
            "e650dd313b00443f8b8bb3f9ae45edc6",
            "f823fadc4c3d40fb932f997637f49402",
            "38451951bd9d469fb81ef9bffdd1f54d",
            "2f7f85dfd2f54e73abb06829945c9c62",
            "0cbefd13691045e8a5d311dfc542abe1",
            "8eaaa347a82d44dabbf66f6a9ea34126",
            "35e37cabc4c648a7a23a801a3b9f2658",
            "bcdb5694c11f41f09ef0cab8221fa7f2",
            "c488e44d7bb74e449f99a5064f52128e",
            "777d7af0dea44b1a98f170fbdae7de8f",
            "d4e4dbcae1304bbc8bb6d52e460998fc"
          ]
        },
        "id": "hnHEsqq68Qup",
        "outputId": "52db47cb-c89e-455a-b3c5-3e2eed014f61"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/49942 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cb3f10f076d402994199134583f69a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e650dd313b00443f8b8bb3f9ae45edc6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_data_sample = train_data.filter(lambda example, index: index % 20 == 0, with_indices=True)\n",
        "val_data_sample = val_data.filter(lambda example, index: index % 20 == 0, with_indices=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSMelU069McP",
        "outputId": "ba4e0beb-1fd5-4ea8-ce2c-21cb5165ad98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['output', 'instruction', 'input', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 2498\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train_data_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlaz0Iwg9Rsd",
        "outputId": "173e3d32-fc24-4620-c642-0b5cc42f0664"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['output', 'instruction', 'input', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 100\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "val_data_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WWg-5mR5Ak0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "28de3188-fc3f-4bcd-ae44-b7b7dead7407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [57/57 2:53:00, Epoch 2.87/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.988991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.905055</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=train_data_sample,\n",
        "    eval_dataset=val_data_sample,\n",
        "    args=transformers.TrainingArguments(\n",
        "        per_device_train_batch_size=MICRO_BATCH_SIZE,\n",
        "        per_device_eval_batch_size=MICRO_BATCH_SIZE,\n",
        "        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
        "        # warmup_steps=1,\n",
        "        num_train_epochs=EPOCHS,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        fp16=True,\n",
        "        logging_steps=train_data_sample.num_rows // MICRO_BATCH_SIZE,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        # save_strategy=\"epoch\",\n",
        "        # eval_steps=4 if VAL_SET_SIZE > 0 else None,\n",
        "        # save_steps=16,\n",
        "        # max_steps=16,\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        # save_total_limit=1,\n",
        "        # load_best_model_at_end=True if VAL_SET_SIZE > 0 else False,\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "# model.config.use_cache = False\n",
        "\n",
        "# old_state_dict = model.state_dict\n",
        "# model.state_dict = (\n",
        "#     lambda self, *_, **__: get_peft_model_state_dict(self, old_state_dict())\n",
        "# ).__get__(model, type(model))\n",
        "\n",
        "# if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
        "#     model = torch.compile(model)\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "model.save_pretrained(OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nv7Lm1cDvvVc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "820894f68fde40e9951d5561df4365ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0f5b279cc8244c09ef9cd5c82bcdf8e",
              "IPY_MODEL_7ab84b901442487884ca1c4ea2f9db30",
              "IPY_MODEL_f12fb5e1a3e84d50908403da32a2096d"
            ],
            "layout": "IPY_MODEL_3fb918ca79724fbaa25bc527e43bb535"
          }
        },
        "e0f5b279cc8244c09ef9cd5c82bcdf8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bf641cab7384731a1186a2462e57bce",
            "placeholder": "​",
            "style": "IPY_MODEL_3bfc37279d2748ef9262e3642282b026",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "7ab84b901442487884ca1c4ea2f9db30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89f6216e60494dcc857a756e47aed9f9",
            "max": 33,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a06f4cb00734e5ea64954c04cf3cfd5",
            "value": 33
          }
        },
        "f12fb5e1a3e84d50908403da32a2096d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a5ac654b01b4eb99fc1426352ac4be7",
            "placeholder": "​",
            "style": "IPY_MODEL_b34cfaf7d7f24839a6068c25a335fd42",
            "value": " 33/33 [01:22&lt;00:00,  2.60s/it]"
          }
        },
        "3fb918ca79724fbaa25bc527e43bb535": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bf641cab7384731a1186a2462e57bce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bfc37279d2748ef9262e3642282b026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89f6216e60494dcc857a756e47aed9f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a06f4cb00734e5ea64954c04cf3cfd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a5ac654b01b4eb99fc1426352ac4be7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b34cfaf7d7f24839a6068c25a335fd42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8782559ca0cb4c74ac74c6c7926f23d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b57b8c2c5c446119f2e2f85f5dbcac3",
              "IPY_MODEL_7df1586c644448f1874d854309248236",
              "IPY_MODEL_aaff45aa894b4b4ebbf18bbe6fdf5948"
            ],
            "layout": "IPY_MODEL_46e179100c9449618080476b947f85df"
          }
        },
        "8b57b8c2c5c446119f2e2f85f5dbcac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96ea26c44f6d400a904fa087a46a544b",
            "placeholder": "​",
            "style": "IPY_MODEL_a64ced2e192a46108372816e8d382841",
            "value": "Map: 100%"
          }
        },
        "7df1586c644448f1874d854309248236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b0dc896c3c2401ebbbc065dc6fcec69",
            "max": 49942,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad235e16402742758d7897528576ed9d",
            "value": 49942
          }
        },
        "aaff45aa894b4b4ebbf18bbe6fdf5948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6970843fd87247aa9929684e0a881ef1",
            "placeholder": "​",
            "style": "IPY_MODEL_b1deb2454c71408288776c6b5d16aed6",
            "value": " 49942/49942 [01:07&lt;00:00, 800.49 examples/s]"
          }
        },
        "46e179100c9449618080476b947f85df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96ea26c44f6d400a904fa087a46a544b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a64ced2e192a46108372816e8d382841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b0dc896c3c2401ebbbc065dc6fcec69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad235e16402742758d7897528576ed9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6970843fd87247aa9929684e0a881ef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1deb2454c71408288776c6b5d16aed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd7e838632ea48579bd3c357b7436f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ee858d1a02f42e2a1672e7102d106ad",
              "IPY_MODEL_98767e931d6546f1b38954727e878d64",
              "IPY_MODEL_65e03b47d35b47298e63c5ff1ebd88b3"
            ],
            "layout": "IPY_MODEL_423d05dff87448ed85e353c417f41729"
          }
        },
        "7ee858d1a02f42e2a1672e7102d106ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7160636e0e0410a8775f6f0078ef27c",
            "placeholder": "​",
            "style": "IPY_MODEL_53e65c0ab3af4b1b829f1505f03afd83",
            "value": "Map: 100%"
          }
        },
        "98767e931d6546f1b38954727e878d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae63829572b24e3e97e0d1e0be4cf52f",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0337c163fb10491dbe7e1df6d023e0ff",
            "value": 2000
          }
        },
        "65e03b47d35b47298e63c5ff1ebd88b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fede4440e00e4f85ab5c786804bd0b98",
            "placeholder": "​",
            "style": "IPY_MODEL_cff58cf8976d4da29fe6afd798dc2e4d",
            "value": " 2000/2000 [00:02&lt;00:00, 909.77 examples/s]"
          }
        },
        "423d05dff87448ed85e353c417f41729": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7160636e0e0410a8775f6f0078ef27c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53e65c0ab3af4b1b829f1505f03afd83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae63829572b24e3e97e0d1e0be4cf52f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0337c163fb10491dbe7e1df6d023e0ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fede4440e00e4f85ab5c786804bd0b98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cff58cf8976d4da29fe6afd798dc2e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cb3f10f076d402994199134583f69a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03ddfe106bf248198691e2f7ff61450f",
              "IPY_MODEL_02e78fe0f3a84e7085d892ba30d3592a",
              "IPY_MODEL_7cf6ee1a47424cac992331483d5ad8b3"
            ],
            "layout": "IPY_MODEL_7c80452949a747579eadcb1d31185168"
          }
        },
        "03ddfe106bf248198691e2f7ff61450f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e08a8e866e804a6fa4307bf25cf13e07",
            "placeholder": "​",
            "style": "IPY_MODEL_ed83a818c1fc447586478516a2dc4e7b",
            "value": "Filter: 100%"
          }
        },
        "02e78fe0f3a84e7085d892ba30d3592a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c9471145ac743fe9ed5ab19d8a36178",
            "max": 49942,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff259bd4733f4910b3219745e1618c55",
            "value": 49942
          }
        },
        "7cf6ee1a47424cac992331483d5ad8b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9251c5e978d34464aafb4abfddcce508",
            "placeholder": "​",
            "style": "IPY_MODEL_5a56262fa299420190eea3a8d0faf669",
            "value": " 49942/49942 [00:15&lt;00:00, 2176.43 examples/s]"
          }
        },
        "7c80452949a747579eadcb1d31185168": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e08a8e866e804a6fa4307bf25cf13e07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed83a818c1fc447586478516a2dc4e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c9471145ac743fe9ed5ab19d8a36178": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff259bd4733f4910b3219745e1618c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9251c5e978d34464aafb4abfddcce508": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a56262fa299420190eea3a8d0faf669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e650dd313b00443f8b8bb3f9ae45edc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f823fadc4c3d40fb932f997637f49402",
              "IPY_MODEL_38451951bd9d469fb81ef9bffdd1f54d",
              "IPY_MODEL_2f7f85dfd2f54e73abb06829945c9c62"
            ],
            "layout": "IPY_MODEL_0cbefd13691045e8a5d311dfc542abe1"
          }
        },
        "f823fadc4c3d40fb932f997637f49402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8eaaa347a82d44dabbf66f6a9ea34126",
            "placeholder": "​",
            "style": "IPY_MODEL_35e37cabc4c648a7a23a801a3b9f2658",
            "value": "Filter: 100%"
          }
        },
        "38451951bd9d469fb81ef9bffdd1f54d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcdb5694c11f41f09ef0cab8221fa7f2",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c488e44d7bb74e449f99a5064f52128e",
            "value": 2000
          }
        },
        "2f7f85dfd2f54e73abb06829945c9c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_777d7af0dea44b1a98f170fbdae7de8f",
            "placeholder": "​",
            "style": "IPY_MODEL_d4e4dbcae1304bbc8bb6d52e460998fc",
            "value": " 2000/2000 [00:00&lt;00:00, 2210.13 examples/s]"
          }
        },
        "0cbefd13691045e8a5d311dfc542abe1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eaaa347a82d44dabbf66f6a9ea34126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35e37cabc4c648a7a23a801a3b9f2658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcdb5694c11f41f09ef0cab8221fa7f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c488e44d7bb74e449f99a5064f52128e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "777d7af0dea44b1a98f170fbdae7de8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4e4dbcae1304bbc8bb6d52e460998fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}